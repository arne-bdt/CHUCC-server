# CHUCC Server - Task Roadmap

This directory contains task breakdowns for implementing the remaining SPARQL 1.2 Protocol Version Control Extension endpoints. Each task is designed to be completable in one development session (3-6 hours).

---

## Status: COMPLETED

**Previously:** All original tasks were completed and removed (October 24, 2025)

**Now:** All feature tasks completed! Only optional technical debt remains.

**Recent Completions:**
- SPARQL 1.1 Service Description - All 6 phases (2025-11-10) ‚úÖ
- Naming Conventions - All 4 tasks (2025-11-09) ‚úÖ
- Test Output Quality - Eliminate Kafka Topic Warnings (2025-11-08) ‚úÖ
- Dataset Routing Standardization (2025-11-07) ‚úÖ
- Nested Transaction Fix (2025-11-07) ‚úÖ
- Batch Operations API (2025-11-03) ‚úÖ
- Blame API (2025-11-02) ‚úÖ
- History & Diff API (2025-11-01) ‚úÖ
- Merge Operations API (All phases - 2025-10-28) ‚úÖ
- Materialized Views (All 6 tasks - 2025-10-26 to 2025-10-28) ‚úÖ
- Parallel Event Replay (Simplified approach - 2025-10-28) ‚úÖ
- patchSize Schema Evolution (2025-01-24) ‚úÖ
- Branch Management API (2025-10-24) ‚úÖ
- Dataset Management + Kafka Integration (2025-10-26) ‚úÖ

---

## Remaining Tasks

### üü¢ In Progress - Prefix Management Protocol

#### 1. Prefix Management Protocol (PMP) Implementation
**Directory:** `.tasks/pmp/`
**Status:** üü° In Progress (Session 1 completed, 3 remaining)
**Priority:** Medium
**Category:** Standards Compliance / IDE Integration

**Overview:**
Implement REST API for managing RDF namespace prefixes with version control. Enables IDE integration, preserves RDF/XML namespace declarations, and supports SPARQL query template generation.

**Sessions:**
1. ‚úÖ Core Implementation (GET/PUT/PATCH/DELETE) - Completed 2025-11-11
2. ‚úÖ Time-Travel Support (commit-based prefix queries) - Completed 2025-11-11
3. ‚è≥ Suggested Prefixes (namespace discovery)
4. ‚è≥ OpenAPI and Comprehensive Testing

**Completed Work (Sessions 1-2):**
- ‚úÖ UpdatePrefixesCommandHandler (PA/PD directive generation)
- ‚úÖ PrefixManagementController (5 endpoints)
- ‚úÖ DTOs (UpdatePrefixesRequest, PrefixResponse, CommitResponse)
- ‚úÖ Enhanced RdfPatchUtil.isNoOp() to detect prefix changes
- ‚úÖ Time-travel endpoint: GET /commits/{id}/prefixes
- ‚úÖ Integration with DatasetService.materializeAtCommit()
- ‚úÖ 18 integration tests + 7 unit tests (all passing)
- ‚úÖ Zero quality violations
- ‚úÖ CQRS compliance verified, test isolation validated

**Estimated Time:** 10-14 hours total (7 hours completed, 3-7 hours remaining)

**Benefits:**
- Store prefixes in version control (RDFPatch PA/PD directives)
- Time-travel prefix queries (query prefixes at any commit)
- IDE auto-completion for SPARQL queries
- Preserve RDF/XML namespace declarations
- Reduce manual typing errors
- Historical state reconstruction via event replay

**Next Step:** Begin [Session 3: Suggested Prefixes](.tasks/pmp/session-3-suggested-prefixes.md)

---

### ‚úÖ Completed Tasks - REST Best Practices

#### 1. ‚úÖ Add Pagination to Collection Endpoints (COMPLETED 2025-11-10)

**Overview:**
Added `offset` and `limit` pagination parameters to all collection endpoints that previously returned all results (branches, tags, refs).

**Endpoints Updated:**
1. ‚úÖ `GET /{dataset}/version/branches` - BranchController (COMPLETED 2025-11-10)
2. ‚úÖ `GET /{dataset}/version/tags` - TagController (COMPLETED 2025-11-10)
3. ‚úÖ `GET /{dataset}/version/refs` - RefsController (COMPLETED 2025-11-10)

**Total Estimated Time:** 6-8 hours (2-3 hours per endpoint)
**Actual Time:** 6.5 hours (all 3 tasks completed)

**Benefits Achieved:**
- Performance with large datasets (prevent memory exhaustion)
- Consistent API behavior (all list endpoints now have pagination)
- Better client UX (incremental data loading)
- Scalability support (1000s of branches/tags/refs)
- RFC 5988 Link headers for next page navigation

**Status:** ‚úÖ COMPLETED
**Priority:** Medium (REST best practice, not protocol-mandated)
**Session:** claude/audit-offset-limit-params-011CUtpRzJtQsm1pZ6Cda2j6

**Task 1 Summary (Branches):**
- Added pagination to BranchController (limit/offset/Link headers)
- Updated BranchService with pagination logic
- Modified BranchListResponse to include PaginationInfo
- Created comprehensive test suite (5 integration + 3 unit tests)
- Code review: Grade A, CQRS compliant
- All quality gates passed

**Task 2 Summary (Tags):**
- Added pagination to TagController following same pattern
- Updated TagService with limit/offset parameters
- Modified TagListResponse to include PaginationInfo
- Created PaginationValidator utility to eliminate code duplication
- Created comprehensive test suite (5 integration + 3 unit tests)
- All quality gates passed (Checkstyle, SpotBugs, PMD, CPD)

**Task 3 Summary (Refs):**
- Added pagination to RefsController with limit/offset parameters
- Updated RefService with pagination logic
- Converted RefsListResponse to record pattern with PaginationInfo
- Created comprehensive test suite (6 integration + 3 unit tests)
- Updated existing RefsControllerTest for new signature (5 tests)
- All quality gates passed (Checkstyle, SpotBugs, PMD)
- Total test count: ~1419 tests

---

### üü¢ Optional Enhancement (Standards Compliance)

No remaining tasks in this category.

---

### üîµ Low Priority (Technical Debt)

#### 3. Fix CreateBranchCommandHandler Write-Through Pattern
#### 3. Fix CreateBranchCommandHandler Write-Through Pattern
**File:** TBD

**Problem:**
- `CreateBranchCommandHandler` only publishes events, doesn't write to repository
- Inconsistent with `CreateDatasetCommandHandler` which uses write-through pattern
- Breaks test infrastructure when projector is disabled
- Identified by cqrs-compliance-checker during test isolation fix (2025-11-06)

**Solution:**
- Add repository write BEFORE event publication (write-through pattern)
- Make `ReadModelProjector` idempotent for `BranchCreatedEvent`
- Update projector to check if branch exists before saving
- Maintain consistency across all command handlers

**Status:** TODO
**Estimated Time:** 2-3 hours
**Category:** Architecture Fix
**Complexity:** Medium
**Impact:** Affects all tests, breaks projector-disabled mode

**Benefits:**
- Consistent command handler pattern across codebase
- Works in both projector-enabled and projector-disabled modes
- HTTP responses return after repository update (better UX)
- Projectors become pure idempotent replay handlers

**Note:** Pre-existing issue discovered during test isolation refactoring, not introduced by recent changes.

---

### üü† Critical (Infrastructure)

#### 4. ‚úÖ Dataset Management with Kafka Topic Integration - COMPLETED
**Status:** ‚úÖ COMPLETED (2025-10-26)

**Completed Tasks:**
1. ‚úÖ **Dataset Creation Endpoint** (Critical)
   - `POST /version/datasets/{name}` - Create dataset with automatic Kafka topic creation
   - Completed: See commit a91f9f2

2. ‚úÖ **Production Kafka Config** (Critical)
   - Updated Kafka configuration for production (RF=3, partitions=6)
   - Completed: See commit 0ad6c89

3. ‚úÖ **Error Handling** (Important)
   - Robust error handling for topic creation failures with retry logic
   - Completed: See commit 353ee54

4. ‚úÖ **Monitoring & Metrics** (Important)
   - Comprehensive monitoring for dataset/topic lifecycle via Micrometer
   - Completed: See commit 654ba92

5. ‚è≠Ô∏è **Per-Dataset Tuning** (Future)
   - Custom Kafka configuration per dataset
   - Status: Skipped (future enhancement)

6. ‚úÖ **Topic Health Checks** (Simplified)
   - Manual health checks and healing endpoints (no auto-healing or scheduled checks)
   - Completed: See commit 6612682

**Deliverables:**
- ‚úÖ Dataset creation/deletion endpoints
- ‚úÖ Automatic Kafka topic provisioning with production settings
- ‚úÖ RFC 7807 error handling with retry logic
- ‚úÖ Health monitoring endpoints (`/actuator/kafka/health-detailed`)
- ‚úÖ Manual topic healing (`/actuator/kafka/topics/{dataset}/heal?confirm=true`)
- ‚úÖ Comprehensive metrics via Micrometer

---

## Progress Summary

**Feature Tasks:** ‚úÖ ALL COMPLETED

**Architecture/Technical Debt:** 1 task (optional improvement - 2-3 hours)

**Total Endpoints Remaining:** 0 endpoints (all implemented!)
**Total Estimated Time:**
- Protocol Endpoints: ‚úÖ COMPLETED
- Technical Debt: 2-3 hours (optional - CreateBranchCommandHandler write-through pattern)

**Priority Breakdown:**
- üü° Medium Priority: 1 task (Pagination - 6-8 hours)
- üü¢ Optional Enhancement: 1 task (Service Description - 12-16 hours)
- üîµ Low Priority: 1 task (CreateBranchCommandHandler write-through - 2-3 hours)

**Current Status:** All feature tasks and major architecture refactoring completed (100%)
- ‚úÖ CommitCreatedEvent patchSize (completed 2025-01-24)
- ‚úÖ Revert/CherryPick patchSize (completed 2025-01-25)
- ‚úÖ Commit Metadata API (completed 2025-01-25)
- ‚úÖ Branch Management API (completed 2025-10-24)
- ‚úÖ Tag Management API (completed 2025-10-25)
- ‚úÖ Dataset Management + Kafka Integration (completed 2025-10-26)
- ‚úÖ Squash/Rebase Pure CQRS Refactoring (completed 2025-11-06)
- ‚úÖ Integration Test Isolation (completed 2025-11-06)

---

## Recommended Implementation Order

### ‚úÖ Infrastructure (Critical) - COMPLETED

**Status:** All infrastructure tasks completed (2025-10-26 to 2025-10-28)

1. ‚úÖ **Dataset Management + Kafka Integration** (completed 2025-10-26)
   - Dynamic dataset creation with automatic topic provisioning
   - Production Kafka configuration (RF=3, partitions=6)
   - Error handling with retry logic
   - Monitoring and health checks

2. ‚úÖ **Materialized Views** (completed 2025-10-26 to 2025-10-27)
   - 10-20x faster branch HEAD queries
   - LRU eviction for memory management
   - Monitoring and recovery mechanisms

3. ‚úÖ **Fail-Fast Projection Error Handling** (completed 2025-10-28)
   - Kafka retry with exponential backoff
   - Dead Letter Queue (DLQ) for failed events
   - Comprehensive error metrics

4. ‚úÖ **Parallel Event Replay** (completed 2025-10-28)
   - Configurable consumer concurrency
   - 6x faster startup with parallel processing
   - Event processing timing metrics

---

### Feature Implementation

**Recommended Order (Start Simple, Build Up):**

1. **Blame API** (3-4 hours) ‚≠ê **Start here**
   - Read-only operation
   - More complex: reverse history traversal
   - Interesting algorithm (BFS with quad tracking)
   - Good challenge after simpler tasks

2. **Batch Operations API** (4-5 hours)
   - Write operations (CQRS)
   - Complex but modular
   - Reuses existing query/update logic
   - Performance optimization for bulk operations

### Infrastructure (Future/Optional)

**Recommended:** Defer until after feature implementation is complete.

3. **Per-Dataset Tuning** (4-5 hours)
   - Allows custom Kafka config per dataset
   - Nice-to-have for advanced use cases
   - Can be added later without breaking changes

4. **Topic Health Checks** (4-5 hours)
   - Automated health checks and self-healing
   - Improves operational reliability
   - Can be added incrementally

### Architecture/Technical Debt (Optional)

This remaining task improves consistency across command handlers:

**‚úÖ Refactor Squash/Rebase to Pure CQRS** - COMPLETED (2025-11-06)

**Fix CreateBranchCommandHandler Write-Through Pattern** (2-3 hours)
   - Medium complexity, targeted fix
   - Adds write-through pattern to CreateBranchCommandHandler
   - Makes projector idempotent for BranchCreatedEvent
   - Improves consistency with CreateDatasetCommandHandler
   - **Recommended:** Optional improvement, not critical for production

---

## Already Implemented Features

The following endpoints are **already implemented** and working:

### ‚úÖ Advanced Operations (All Implemented)
- `POST /version/reset` - Reset branch pointer
- `POST /version/cherry-pick` - Cherry-pick commit
- `POST /version/revert` - Revert commit
- `POST /version/rebase` - Rebase branch
- `POST /version/squash` - Squash commits

**Controller:** [AdvancedOpsController.java](../src/main/java/org/chucc/vcserver/controller/AdvancedOpsController.java)

### ‚úÖ Branch Operations (All Implemented - 2025-10-24)
- `GET /version/branches` - List all branches with full metadata
- `POST /version/branches` - Create new branch from commit/branch
- `GET /version/branches/{name}` - Get branch information
- `DELETE /version/branches/{name}` - Delete branch

**Controller:** [BranchController.java](../src/main/java/org/chucc/vcserver/controller/BranchController.java)

### ‚úÖ Tag Operations (All Implemented - 2025-10-25)
- `GET /version/tags` - List all tags with message and author
- `POST /version/tags` - Create new immutable tag
- `GET /version/tags/{name}` - Get tag details
- `DELETE /version/tags/{name}` - Delete tag

**Controller:** [TagController.java](../src/main/java/org/chucc/vcserver/controller/TagController.java)

### ‚úÖ Commit Operations (Partial)
- `POST /version/commits` - Create commit (apply RDF Patch)

**Note:** Commit metadata endpoint still needs implementation

### ‚úÖ Graph Store Protocol
- `GET/PUT/POST/DELETE` - All GSP operations
- Batch graphs operations
- Named graph support
- Version control selectors

---

## Task File Structure

Each task file includes:

1. **Overview** - What needs to be implemented
2. **Current State** - What's already done
3. **Requirements** - API specification
4. **Implementation Steps** - Detailed step-by-step guide
5. **Success Criteria** - Definition of done
6. **Testing Strategy** - Test approach (API vs Projector tests)
7. **Files to Create/Modify** - Complete file list
8. **References** - Links to protocol specs and code

---

## Development Guidelines

### Before Starting a Task

1. Read the task file completely
2. Review the protocol specification
3. Check existing similar implementations for patterns
4. Plan test cases

### During Implementation

1. Follow TDD (write tests first)
2. Use `-q` flag for Maven commands
3. Run static analysis before tests: `mvn -q compile checkstyle:check spotbugs:check`
4. Implement incrementally (DTOs ‚Üí Command/Event ‚Üí Handler ‚Üí Controller)
5. **Invoke specialized agents** after implementation:
   - `@cqrs-compliance-checker` after command/projector changes
   - `@test-isolation-validator` after writing tests
   - `@event-schema-evolution-checker` after modifying events

### After Implementation

1. Run full build: `mvn -q clean install`
2. Verify zero quality violations
3. Create conventional commit message
4. **Delete the task file** when completed
5. Update this README (move task to "Completed Tasks" section)

---

## Testing Strategy

### API Layer Tests (90% of tests)
- Projector **DISABLED** by default
- Test HTTP status codes and headers
- Do **NOT** query repositories
- Example: `BranchControllerIT`

### Projector Tests (10% of tests)
- Projector **ENABLED** via `@TestPropertySource(properties = "projector.kafka-listener.enabled=true")`
- Use `await()` pattern for async verification
- Test event projection to repositories
- Example: `ReadModelProjectorIT`

See [Development Guidelines](../.claude/CLAUDE.md) for detailed testing patterns.

---

## Success Criteria for All Tasks

- ‚úÖ All endpoints return appropriate responses (no 501)
- ‚úÖ DTOs created with validation
- ‚úÖ CQRS pattern followed (Command ‚Üí Event ‚Üí Projector)
- ‚úÖ Integration tests pass (API layer)
- ‚úÖ Unit tests pass (command handlers)
- ‚úÖ Zero quality violations (Checkstyle, SpotBugs, PMD, compiler warnings)
- ‚úÖ Full build passes: `mvn -q clean install`
- ‚úÖ Task file deleted after completion

---

## Protocol Compliance

All tasks implement endpoints from:
- **[SPARQL 1.2 Protocol Version Control Extension](../protocol/SPARQL_1_2_Protocol_Version_Control_Extension.md)**
- **[Graph Store Protocol Version Control Extension](../protocol/SPARQL_1_2_Graph_Store_Protocol_Version_Control_Extension.md)**

### Required Endpoints (Normative)
- ‚úÖ Commit creation (`POST /version/commits`)
- ‚úÖ Refs listing (`GET /version/refs`)
- ‚úÖ Branch management (`GET/POST/GET/{name} /version/branches`)
- ‚úÖ Commit metadata (`GET /version/commits/{id}`)
- ‚úÖ Tag management (`GET/POST /version/tags`)
- ‚úÖ Merge operations (`POST /version/merge`)
- ‚úÖ History listing (`GET /version/history`)
- ‚úÖ Batch operations (`POST /version/batch`)

### Optional Endpoints (Extensions)
- ‚úÖ Diff (`GET /version/diff`)
- ‚úÖ Blame (`GET /version/blame`)
- ‚úÖ Advanced operations (cherry-pick, revert, reset, rebase, squash)

---

## Completed Tasks (2025)

### ‚úÖ SPARQL 1.1 Service Description (Completed 2025-11-10)
**File:** `.tasks/service-description/` (DELETED - tasks completed)

**Endpoints:**
- ‚úÖ `GET /.well-known/void` - Service description (well-known URI)
- ‚úÖ `GET /service-description` - Service description (explicit endpoint)

**Status:** ‚úÖ Completed (2025-11-10)
**Category:** Standards Compliance / Discoverability
**W3C Spec:** SPARQL 1.1 Service Description
**Total Time:** 14 hours (6 phases)

**Implementation:**
- Created ServiceDescriptionService (RDF model generation)
- Created ServiceDescriptionController (content negotiation)
- Implemented dynamic dataset discovery
- Defined custom vc: vocabulary for version control
- Exposed branches, tags, commits metadata
- Content negotiation (Turtle, JSON-LD, RDF/XML, N-Triples)
- Added 24 integration tests (all passing)
- Comprehensive documentation and examples

**Files Created:**
- `src/main/java/org/chucc/vcserver/service/ServiceDescriptionService.java`
- `src/main/java/org/chucc/vcserver/controller/ServiceDescriptionController.java`
- `src/test/java/org/chucc/vcserver/integration/ServiceDescriptionIT.java`
- `docs/api/version-control-vocabulary.md`
- `docs/examples/service-description-examples.md`

**Files Modified:**
- `src/main/java/org/chucc/vcserver/repository/BranchRepository.java`
- `docs/api/openapi-guide.md`
- `docs/architecture/c4-level3-component.md`
- `README.md`

---

### ‚úÖ Test Output Quality - Eliminate Kafka Topic Warnings (Completed 2025-11-08)

**Status:** ‚úÖ COMPLETED (2025-11-08)
**Category:** Test Infrastructure / Quality
**Actual Time:** 4 hours

**Problem:**
- Integration tests generating 175+ "Topic already exists" warnings
- Kafka topics persist across test methods within a test class
- CreateDatasetCommandHandler attempting to create topics multiple times
- Test output polluted, making it hard to spot real issues

**Solution:**
- Added static `Set<String> datasetsWithTopics` to track created topics
- First test method: Creates dataset via CreateDatasetCommandHandler (creates Kafka topics)
- Subsequent test methods: Uses `createInitialStateDirectly()` to bypass topic creation
- Both methods create identical state (commit, branch, dataset cache, materialized graph)
- Thread-safe implementation using ConcurrentHashMap.newKeySet()

**Code Improvements:**
- Refactored materialized graph creation logic for better encapsulation
- Both setup methods now handle their own materialized graph creation
- Clearer separation of concerns between first and subsequent test methods

**Documentation Updates:**
- Added ITFixture topic tracking explanation to .claude/CLAUDE.md
- Updated test count in README.md (1244 ‚Üí 1252)

**Test Results:**
- ‚úÖ All 1252 tests passing (834 unit + 418 integration)
- ‚úÖ Zero "Topic already exists" warnings (down from 175+)
- ‚úÖ BUILD SUCCESS

**Files Modified:**
- `src/test/java/org/chucc/vcserver/testutil/ITFixture.java`
- `.claude/CLAUDE.md`
- `README.md`

**Agent Validation:**
- code-reviewer: ‚úÖ PRODUCTION-READY - Excellent state replication
- test-isolation-validator: ‚úÖ PASS - Tests properly isolated
- documentation-sync-agent: ‚úÖ Critical docs updated

**Benefits:**
- Clean test output (warnings eliminated)
- Preserved warnings as useful signals for genuine issues
- Better test developer experience
- Consistent setup across all integration tests

---

### ‚úÖ Batch Operations API (Completed 2025-11-03)
**File:** `.tasks/batch/01-implement-batch-operations-api.md` (DELETED - task completed)

**Endpoint:**
- ‚úÖ `POST /version/batch` - Combine multiple write operations (SPARQL updates or RDF patches) into single commit

**Status:** ‚úÖ Completed (2025-11-03)
**Category:** Version Control Protocol
**Protocol Spec:** ¬ß3.6
**Estimated Time:** 4-5 hours (actual: 6+ hours including test isolation fixes)

**Implementation:**
- Created DTOs: BatchWriteRequest, WriteOperation, BatchWriteResponse
- Created BatchOperationService (combines operations into single RDF patch)
- Updated BatchController (replaced 501 stub with full implementation)
- Reuses existing CreateCommitCommandHandler (no new events needed)
- Single commit mode only (simplified from original complex design)
- Write-only operations (SPARQL updates and RDF patches)
- All operations must target same branch
- Added 10 integration tests (BatchOperationsIT)
- Added 9 unit tests (BatchOperationServiceTest)

**Design Decisions:**
- Simplified from original plan (removed query operations, atomic rollback)
- Write-only operations (CQRS compliant)
- Single commit mode only (cleaner history)
- Reuses CommitCreatedEvent (no new event types needed)
- Controller orchestrates, service combines patches, handler publishes event
- Validation upfront (fail-fast)
- Test isolation pattern: projector disabled (API layer tests)

**Critical Fix:**
- Test isolation violation fixed (removed incorrect projector enablement)
- All 10 integration tests now passing with projector disabled
- Corrected Javadoc to explain why projector not needed for batch operations

**Files Created:**
- `src/main/java/org/chucc/vcserver/dto/WriteOperation.java`
- `src/main/java/org/chucc/vcserver/dto/BatchWriteRequest.java`
- `src/main/java/org/chucc/vcserver/dto/BatchWriteResponse.java`
- `src/main/java/org/chucc/vcserver/service/BatchOperationService.java`
- `src/test/java/org/chucc/vcserver/integration/BatchOperationsIT.java`
- `src/test/java/org/chucc/vcserver/service/BatchOperationServiceTest.java`

**Files Modified:**
- `src/main/java/org/chucc/vcserver/controller/BatchController.java`
- `src/test/java/org/chucc/vcserver/integration/CrossProtocolInteroperabilityIT.java`

**Agent Verification:**
- CQRS Compliance: ‚úÖ FULLY COMPLIANT
- Test Isolation: ‚úÖ VIOLATIONS FIXED (projector enablement removed)
- Documentation Sync: Multiple docs identified for update

---

### ‚úÖ Architecture Refactoring - Pure CQRS (Completed 2025-11-06)

#### Refactor Squash/Rebase Handlers to Pure CQRS
**Status:** ‚úÖ COMPLETED (2025-11-06)
**Category:** Architectural Refactoring
**Estimated Time:** 8-12 hours
**Complexity:** High

**Problem:**
- `SquashCommandHandler` and `RebaseCommandHandler` wrote directly to repository
- Violated CQRS pattern (dual-write, no event replay)
- Broke eventual consistency promise

**Solution:**
- Enriched events with full commit data (patch, patchSize, parents)
- Removed repository writes from command handlers
- Let projector handle all repository updates

**Files Modified:**
- `src/main/java/org/chucc/vcserver/event/CommitsSquashedEvent.java`
- `src/main/java/org/chucc/vcserver/event/BranchRebasedEvent.java`
- `src/main/java/org/chucc/vcserver/command/SquashCommandHandler.java`
- `src/main/java/org/chucc/vcserver/command/RebaseCommandHandler.java`
- `src/main/java/org/chucc/vcserver/projection/ReadModelProjector.java`
- 20+ test files for event schema updates

**Note:** Events now contain full commit data. Command handlers no longer write to repositories.

---

### ‚úÖ Nested Transaction Fix (Completed 2025-11-07)

#### Fix "Transactions cannot be nested!" Error in DatasetService
**Status:** ‚úÖ COMPLETED (2025-11-07)
**Category:** Bug Fix / Architecture
**Actual Time:** 3 hours

**Problem:**
- `DatasetService.applyPatchHistorySince()` used `RDFPatchOps.applyChange()` which internally tries to begin a transaction
- When DatasetGraph already has active transaction (test isolation issue), caused "Transactions cannot be nested!" error
- BatchOperationsProjectorIT failed when run with other integration tests
- Pre-existing issue exposed by routing migration test runs

**Solution:**
- Created `applyPatchWithoutTransactionManagement()` method using custom RDFChangesApply
- Skips transaction operations (txnBegin/txnCommit/txnAbort) when not needed for in-memory graphs
- Same pattern as `InMemoryMaterializedBranchRepository.applyPatchDirect()`
- Added defensive transaction abort checks in graph retrieval paths
- Improved logging (changed ERROR to WARN for non-error conditions)

**Files Modified:**
- `src/main/java/org/chucc/vcserver/service/DatasetService.java` - Added transaction-skipping patch application
- `src/main/java/org/chucc/vcserver/service/BatchOperationService.java` - Added logger and defensive checks
- `src/main/java/org/chucc/vcserver/repository/InMemoryMaterializedBranchRepository.java` - Enhanced cleanup

**Agent Validation:**
- CQRS compliance: ‚úÖ FULLY COMPLIANT - All changes maintain proper boundaries
- Code review: ‚úÖ PRODUCTION-READY with minor logging improvements applied

**Test Results:**
- ‚úÖ All 91 integration tests passing (no test isolation failures)
- ‚úÖ BatchOperationsProjectorIT works correctly with other tests
- ‚úÖ Zero nested transaction errors

**Note:** This fix improves robustness of read model materialization and resolves test isolation edge cases.

---

### ‚úÖ Dataset Routing Standardization (Completed 2025-11-07)

#### Migrate Controllers to Dataset-in-Path Routing (Apache Jena Fuseki Pattern)
**Status:** ‚úÖ COMPLETED (2025-11-07)
**Category:** Refactoring / API Standardization
**Actual Time:** 4 hours

**Goal:**
Standardize all version control endpoints to use dataset as path parameter (`/{dataset}/version/{endpoint}`) instead of query parameter (`/version/{endpoint}?dataset=X`), following Apache Jena Fuseki's RESTful pattern.

**Controllers Migrated:**
1. ‚úÖ BranchController and CommitController (Session 1)
2. ‚úÖ MergeController and HistoryController (Session 1)
3. ‚úÖ AdvancedOpsController (reset, revert, cherry-pick, rebase, squash) (Session 2)
4. ‚úÖ RefsController (Session 2)
5. ‚úÖ BatchController and BatchGraphsController (Session 2)
6. ‚úÖ TagController (already migrated)
7. ‚úÖ GraphStoreController (already correct)

**Pattern:**
```java
// Before:
@RequestMapping("/version")
public ResponseEntity<?> operation(@RequestParam(defaultValue="default") String dataset)

// After:
@RequestMapping("/{dataset}/version")
public ResponseEntity<?> operation(@PathVariable String dataset)
```

**Integration Tests Updated:**
- 76 tests in 9 controller test files (History, Diff, Blame, Reset, Revert, CherryPick, Rebase, Squash, Refs)
- 15 batch-related tests
- CrossProtocolInteroperabilityIT (comprehensive workflow tests)

**Files Modified:**
- 8 controller files
- 12 integration test files
- GraphStoreController Location headers fixed

**Benefits:**
- RESTful resource hierarchy (follows industry standards)
- Consistent with Apache Jena Fuseki pattern
- Better URL structure for API discoverability
- Improved developer experience

**Test Results:**
- ‚úÖ All 91+ integration tests passing
- ‚úÖ Zero routing errors
- ‚úÖ All quality checks passing (Checkstyle, SpotBugs, PMD)

---

### ‚úÖ Integration Test Isolation (Completed 2025-11-06)

#### Fix RebaseIT and SquashIT Test Isolation
**Status:** ‚úÖ COMPLETED (2025-11-06)
**Category:** Test Architecture
**Actual Time:** 4 hours

**Problem:**
- RebaseIT and SquashIT used direct repository writes in setup
- Violated CQRS/Event Sourcing pattern
- Failed when run in full test suite due to cross-test contamination
- Used static dataset names causing Kafka topic conflicts

**Solution:**
- Extended ITFixture for cleanup synchronization
- Implemented unique dataset names per test run (`rebase-test-<nanotime>`, `squash-test-<nanotime>`)
- Event-driven setup via `createBranchViaCommand()` helper
- Removed all direct repository writes
- Proper test isolation with CLEANUP_LOCK synchronization

**Files Modified:**
- `src/test/java/org/chucc/vcserver/integration/RebaseIT.java`
- `src/test/java/org/chucc/vcserver/integration/SquashIT.java`
- `src/test/java/org/chucc/vcserver/testutil/ITFixture.java`

**Agent Validation:**
- test-isolation-validator: ‚úÖ PASS - Tests properly isolated, no changes recommended
- cqrs-compliance-checker: ‚ö†Ô∏è Partial compliance (identified CreateBranchCommandHandler issue as pre-existing)

**Follow-Up:**
- Identified CreateBranchCommandHandler lacks write-through pattern (pre-existing issue)
- See remaining task #1: Fix CreateBranchCommandHandler Write-Through Pattern

---

### ‚úÖ Blame API (Completed 2025-11-02)
**File:** `.tasks/history/03-implement-blame-api.md` (DELETED - task completed)

**Endpoint:**
- ‚úÖ `GET /version/blame` - Last-writer attribution for quads with graph-scoped analysis

**Status:** ‚úÖ Completed (2025-11-02)
**Category:** Version Control Protocol (EXTENSION)
**Protocol Spec:** Extension (not in official SPARQL 1.2 spec)
**Estimated Time:** 3-4 hours (actual: 6+ hours including RDF Patch format debugging)

**Implementation:**
- Created BlameService with graph-scoped blame algorithm
- Created DTOs: QuadBlameInfo, BlameResponse (with pagination)
- Updated HistoryController (replaced 501 stub with full implementation)
- Reverse BFS traversal with quad tracking (handles merge commits correctly)
- Critical delete/re-add handling via quad removal logic
- Pagination support (offset, limit, RFC 5988 Link headers)
- Graph isolation (operates on single graph like git blame on file)
- Added 10 integration tests (9 passing, 1 disabled for default graph investigation)
- Feature flag support: chucc.version-control.blame-enabled=true

**Design Decisions:**
- Read-only operation (no CQRS commands/events needed)
- Required parameters: dataset, commit, graph
- BFS traversal ensures correct handling of merge commits
- Quad removal prevents incorrect blame for delete/re-add scenarios
- Graph-scoped operation (similar to git blame for single file)
- MAX_LIMIT=1000 for DoS protection
- Deterministic sorting (subject, predicate, object) for stable pagination
- Returns immediately with synchronized data (no eventual consistency)

**Bug Discovered:**
- RDF Patch format: Quads use `A S P O G .` (graph LAST), not `A G S P O .`
- Fixed test patches to use correct quad format

**Known Limitation:**
- Default graph support disabled (pending investigation of Jena's internal default graph node representation)
- Named graphs work perfectly

**Files Created:**
- `src/main/java/org/chucc/vcserver/dto/QuadBlameInfo.java`
- `src/main/java/org/chucc/vcserver/dto/BlameResponse.java`
- `src/main/java/org/chucc/vcserver/service/BlameService.java`
- `src/test/java/org/chucc/vcserver/integration/BlameEndpointIT.java`

**Files Modified:**
- `src/main/java/org/chucc/vcserver/controller/HistoryController.java`

**Agent Verification:**
- Code Review: EXCELLENT (9/10) - Production-ready
- CQRS Compliance: FULLY COMPLIANT - Perfect read-side implementation
- Documentation Sync: Multiple docs updated

---

### ‚úÖ Diff API (Completed 2025-11-01)
**File:** `.tasks/history/02-implement-diff-api.md` (DELETED - task completed)

**Endpoint:**
- ‚úÖ `GET /version/diff` - Diff two commits (returns RDF Patch)

**Status:** ‚úÖ Completed (2025-11-01)
**Category:** Version Control Protocol (EXTENSION)
**Protocol Spec:** Extension (not in official SPARQL 1.2 spec)
**Estimated Time:** 1 hour (actual)

**Implementation:**
- Created DiffService for computing diffs between commits
- Updated HistoryController (replaced 501 stub with full implementation)
- Leverages existing DatasetService.materializeCommit() for snapshot loading
- Uses RdfPatchUtil.diff() for quad-level comparison
- Supports diffs between any two commits (not just parent-child)
- Added 9 integration tests (DiffEndpointIT)
- Feature flag support: chucc.version-control.diff-enabled=true

**Design Decisions:**
- Read-only operation (no CQRS commands/events needed)
- Uses existing snapshot caching infrastructure (Caffeine cache)
- Materializes both commit states in memory (O(n+m) where n,m = quad counts)
- Returns text/rdf-patch format
- Additions: quads in 'to' but not in 'from'
- Deletions: quads in 'from' but not in 'to'
- No relationship validation (works for any two commits)

**Files Created:**
- `src/main/java/org/chucc/vcserver/service/DiffService.java`
- `src/test/java/org/chucc/vcserver/integration/DiffEndpointIT.java`

**Files Modified:**
- `src/main/java/org/chucc/vcserver/controller/HistoryController.java`

---

### ‚úÖ History Listing API (Completed 2025-11-01)
**File:** `.tasks/history/01-implement-history-api.md` (DELETED - task completed)

**Endpoint:**
- ‚úÖ `GET /version/history` - List commit history with filters and pagination

**Status:** ‚úÖ Completed (2025-11-01)
**Category:** Version Control Protocol
**Protocol Spec:** ¬ß3.2
**Estimated Time:** 2-3 hours (actual)

**Implementation:**
- Created DTOs: CommitHistoryInfo, HistoryResponse, PaginationInfo
- Implemented HistoryService with comprehensive filtering
- Updated HistoryController (replaced 501 stub)
- Branch filtering: BFS traversal to find reachable commits
- Date range filtering: since/until parameters (RFC3339/ISO8601)
- Author filtering: exact match, case-sensitive
- Offset-based pagination with RFC 5988 Link headers
- Added 10 integration tests (HistoryListingIT)
- Added 10 unit tests (HistoryServiceTest)

**Optimizations:**
- Fixed N+1 query problem: in-memory commit map for O(1) lookups
- Single-pass stream filtering (lazy evaluation)
- Pagination validation (max 1000 limit, DoS protection)

**Files Created:**
- `src/main/java/org/chucc/vcserver/dto/CommitHistoryInfo.java`
- `src/main/java/org/chucc/vcserver/dto/PaginationInfo.java`
- `src/main/java/org/chucc/vcserver/dto/HistoryResponse.java`
- `src/main/java/org/chucc/vcserver/service/HistoryService.java`
- `src/test/java/org/chucc/vcserver/integration/HistoryListingIT.java`
- `src/test/java/org/chucc/vcserver/service/HistoryServiceTest.java`

**Files Modified:**
- `src/main/java/org/chucc/vcserver/controller/HistoryController.java`

**Design Decisions:**
- Read-only operation (no CQRS commands/events needed)
- Sorting: timestamp descending (newest first)
- Branch filter: BFS with in-memory commit map (performance optimization)
- Pagination: offset-based with hasMore flag (no total count for performance)
- Date parsing: RFC3339/ISO8601 format (Instant.parse)
- URL encoding: manual encoding for Link headers

---

### ‚úÖ Merge Operations API (Completed 2025-10-28)
**File:** `.tasks/merge/` (DELETED - tasks completed)

**Endpoint:**
- ‚úÖ `POST /version/merge` - Merge two refs/commits into target branch

**Status:** ‚úÖ Completed (2025-10-28)
**Category:** Version Control Protocol
**Protocol Spec:** ¬ß3.3

**Implementation:**
- Phase 1: Core merge functionality (fast-forward, three-way merge, conflict detection)
- Phase 2: Conflict resolution strategies ("ours", "theirs") with configurable scope (graph-level, dataset-level)
- Phase 3: Manual resolution - **NOT IMPLEMENTED** (protocol mentions but doesn't define semantics)

**Files Created:**
- `src/main/java/org/chucc/vcserver/dto/MergeRequest.java`
- `src/main/java/org/chucc/vcserver/dto/MergeResponse.java`
- `src/main/java/org/chucc/vcserver/dto/MergeConflict.java`
- `src/main/java/org/chucc/vcserver/command/MergeCommand.java`
- `src/main/java/org/chucc/vcserver/command/MergeCommandHandler.java`
- `src/main/java/org/chucc/vcserver/event/MergeCommitCreatedEvent.java`
- `src/main/java/org/chucc/vcserver/controller/MergeController.java`
- `src/main/java/org/chucc/vcserver/util/MergeUtil.java`
- `src/test/java/org/chucc/vcserver/integration/MergeOperationsIT.java`
- `src/test/java/org/chucc/vcserver/command/MergeCommandHandlerTest.java`

**Design Decisions:**
- Fast-forward modes: "allow", "only", "never"
- Merge strategies: "three-way" (default), "ours", "theirs"
- Conflict scope: "graph" (default), "dataset"
- Manual resolution strategy deferred (not required by protocol)
- Lowest Common Ancestor (LCA) algorithm for merge base
- Graph-level conflict detection by default
- Comprehensive conflict reporting with RFC 7807 errors

---

### ‚úÖ Commit Metadata API (Completed 2025-01-25)
**File:** `.tasks/commits/01-implement-commit-metadata-api.md` (DELETED - task completed)

**Endpoints:**
- ‚úÖ `GET /version/commits/{id}?dataset={name}` - Get commit metadata

**Status:** ‚úÖ Completed (2025-01-25)
**Category:** Version Control Protocol
**Protocol Spec:** ¬ß3.2

**Implementation:**
- Added CommitService (read-only service)
- Added CommitMetadataDto with defensive copying
- Updated CommitController (replaced 501 stub)
- Added integration and unit tests (8 new tests)

**Files Created:**
- `src/main/java/org/chucc/vcserver/service/CommitService.java`
- `src/main/java/org/chucc/vcserver/dto/CommitMetadataDto.java`
- `src/test/java/org/chucc/vcserver/integration/CommitMetadataIT.java`
- `src/test/java/org/chucc/vcserver/service/CommitServiceTest.java`

**Files Modified:**
- `src/main/java/org/chucc/vcserver/controller/CommitController.java`
- `src/test/java/org/chucc/vcserver/controller/CommitControllerTest.java`
- `src/test/java/org/chucc/vcserver/integration/CrossProtocolInteroperabilityIT.java`

**Design Decisions:**
- Read-only operation (no CQRS commands needed)
- Strong ETag support (commits are immutable)
- No branches/tags lists (expensive O(n) scan, use `/version/refs` instead)
- Minimal metadata (id, message, author, timestamp, parents, patchSize)

---

### ‚úÖ Add patchSize to Revert/CherryPick Events (Completed 2025-01-25)
- Added `patchSize` field to `RevertCreatedEvent`
- Added `patchSize` field to `CherryPickedEvent`
- Updated `RevertCommitCommandHandler` to compute patchSize before event creation
- Updated `CherryPickCommandHandler` to compute patchSize before event creation
- Removed business logic from `ReadModelProjector` (now uses event data only)
- Updated all affected tests (10+ test files)
- CQRS compliance verified by specialized agent

**Benefits:**
- Consistent with CommitCreatedEvent pattern
- Business logic properly on write side (command handlers)
- Events fully self-contained for event replay
- Performance: Patch parsed once instead of twice

**Files Modified:**
- Events: RevertCreatedEvent.java, CherryPickedEvent.java
- Handlers: RevertCommitCommandHandler.java, CherryPickCommandHandler.java
- Projector: ReadModelProjector.java
- Tests: 10+ test files

### ‚úÖ Tag Management API (Completed 2025-10-25)
**File:** `.tasks/tags/01-implement-tag-list-and-create-api.md` (DELETED - task completed)

**Endpoints:**
- ‚úÖ `GET /version/tags` - List all tags with message and author
- ‚úÖ `POST /version/tags` - Create new immutable tag

**Status:** ‚úÖ Completed (2025-10-25)
**Category:** Version Control Protocol
**Protocol Spec:** ¬ß3.5

**Implementation:**
- Added TagInfo DTO (unified response for list and create)
- Added CreateTagRequest with validation
- Added TagListResponse with defensive copying
- Updated Tag domain model (message, author, createdAt fields)
- Updated CreateTagCommand and TagCreatedEvent (added message, author)
- Enhanced CreateTagCommandHandler (tag existence validation, commit validation)
- Updated TagService (listTags method)
- Updated TagController (replaced 501 stubs with full implementations)
- Added TagCreatedEvent handler to ReadModelProjector
- Added 10 integration tests in TagOperationsIT

**Design Decisions:**
- Single TagInfo DTO instead of separate CreateTagResponse (DRY)
- 202 Accepted for async CQRS pattern (eventual consistency)
- X-Author header fallback chain: body ‚Üí header ‚Üí "anonymous"
- Tag immutability enforcement (409 Conflict on duplicates)
- Nullable message/author for backward compatibility

**Files Created:**
- `src/main/java/org/chucc/vcserver/dto/TagInfo.java`
- `src/main/java/org/chucc/vcserver/dto/CreateTagRequest.java`
- `src/main/java/org/chucc/vcserver/dto/TagListResponse.java`
- `src/test/java/org/chucc/vcserver/integration/TagOperationsIT.java`

**Files Modified:**
- `src/main/java/org/chucc/vcserver/domain/Tag.java`
- `src/main/java/org/chucc/vcserver/command/CreateTagCommand.java`
- `src/main/java/org/chucc/vcserver/event/TagCreatedEvent.java`
- `src/main/java/org/chucc/vcserver/command/CreateTagCommandHandler.java`
- `src/main/java/org/chucc/vcserver/service/TagService.java`
- `src/main/java/org/chucc/vcserver/controller/TagController.java`
- `src/main/java/org/chucc/vcserver/projection/ReadModelProjector.java`
- 12+ test files (constructor signature updates)

---

### ‚úÖ Branch Management API (Completed 2025-10-24)
- Implemented `GET /version/branches` - List all branches
- Implemented `POST /version/branches` - Create new branch
- Implemented `GET /version/branches/{name}` - Get branch info
- Full Git-like metadata support (timestamps, commit count, protection)

**Files:**
- Controller: [BranchController.java](../src/main/java/org/chucc/vcserver/controller/BranchController.java)
- Service: [BranchService.java](../src/main/java/org/chucc/vcserver/service/BranchService.java)
- Command Handler: [CreateBranchCommandHandler.java](../src/main/java/org/chucc/vcserver/command/CreateBranchCommandHandler.java)

---

### ‚úÖ Materialized Branch Views (Completed 2025-10-26 to 2025-10-28)
**Goal:** Move from on-demand graph materialization to eager materialization for instant query performance.

**Completed Tasks (6 total, 19-25 hours):**
1. ‚úÖ MaterializedBranchRepository Infrastructure (3-4 hours) - 2025-10-26
2. ‚úÖ ReadModelProjector Eager Materialization (4-5 hours) - 2025-10-26
3. ‚úÖ DatasetService Integration (3-4 hours) - 2025-10-27
4. ‚úÖ Monitoring and Recovery Mechanisms (3-4 hours) - 2025-10-27
5. ‚úÖ LRU Eviction for Memory Management (4-5 hours) - 2025-10-27
6. ‚úÖ Fail-Fast Projection Error Handling (2-3 hours) - 2025-10-28

**Benefits Achieved:**
- 10-20x faster branch HEAD queries (<10ms vs 100-200ms)
- Memory usage scales with branches, not history depth
- Production-ready monitoring (/actuator/health/materializedViews)
- Manual rebuild endpoint (/actuator/materialized-views/rebuild)
- LRU eviction prevents OutOfMemoryError
- Kafka retry with exponential backoff + DLQ for failed events
- Comprehensive Micrometer metrics

**CQRS Compliance:** ‚úÖ 100% compliant, approved for production

---

### ‚úÖ Parallel Event Replay (Completed 2025-10-28)
**Goal:** Reduce startup time by processing events in parallel.

**Status:** ‚úÖ Completed (Simpler Approach)
**Implementation Time:** 2-3 hours (metrics + concurrency configuration)

**Completed:**
- Event processing timing metrics (`chucc.projection.event.duration`)
- Configurable consumer concurrency (`kafka.consumer.concurrency`)
- Parallel processing across dataset topics

**Benefits Achieved:**
- 6x faster startup (with 6 datasets and concurrency=6)
- Better CPU utilization (multiple cores used)
- Simple configuration (no partition management)
- Measurement infrastructure in place

**Configuration:**
```yaml
kafka:
  consumer:
    concurrency: 6  # Parallel consumers (default: 1)
```

**Design Decision:** The simpler approach (configurable concurrency) achieves ~90% of the benefit with 1% of the complexity compared to full partitioning strategy.

---

## Completed Work (Before October 2025)

The following major features were completed before these tasks were added:

### ‚úÖ Core CQRS + Event Sourcing (Completed)
- Full event publishing from controllers to Kafka
- ReadModelProjector processes events and updates repositories
- Eventual consistency model validated end-to-end

### ‚úÖ Version Control Features (Completed)
- Time-travel SPARQL queries
- Branch deletion with protection
- Dataset deletion
- Tag get/delete operations
- Advanced operations (reset, cherry-pick, revert, rebase, squash)

### ‚úÖ Performance & Optimization (Completed)
- Snapshot optimization for faster startup
- LRU cache eviction (Caffeine)
- Model API to Graph API migration (20-30% performance gain)

### ‚úÖ Quality & Testing (Completed)
- 1212 tests (all passing)
- Zero quality violations
- Test isolation pattern (projector disabled by default)
- Comprehensive integration test suite

For details on completed work, see git history:
```bash
git log --oneline --since="2025-10-01"
```

---

## Architecture & Documentation

For understanding the implemented system:

- **[Architecture Overview](../docs/architecture/README.md)** - Complete system understanding
- **[CQRS + Event Sourcing Guide](../docs/architecture/cqrs-event-sourcing.md)** - Core pattern explanation
- **[C4 Component Diagram](../docs/architecture/c4-level3-component.md)** - Component structure
- **[Development Guidelines](../.claude/CLAUDE.md)** - "How-to" for development
- **[OpenAPI Guide](../docs/api/openapi-guide.md)** - API documentation

---

## Contributing

See [Contributing Guide](../docs/development/contributing.md) for development workflow.

---

## Task Completion Workflow

When a task is completed:

1. **Verify Success Criteria**
   - All endpoints implemented (no 501)
   - All tests pass
   - Zero quality violations
   - Full build succeeds

2. **Create Commit**
   - Follow conventional commit format
   - Include "Generated with Claude Code" footer

3. **Update This README**
   - Move task from "Remaining Tasks" to "Completed Tasks"
   - Update progress percentage
   - Update endpoint status (‚ùå ‚Üí ‚úÖ)

4. **Delete Task File/Folder**
   - Remove `.tasks/<category>/<task-file>.md`
   - Remove directory if no other tasks remain

5. **Celebrate!** üéâ

---

## Questions?

- Read the task file for detailed implementation steps
- Check protocol specifications for requirements
- Review existing similar implementations for patterns
- Consult [Development Guidelines](../.claude/CLAUDE.md) for best practices

---

**Last Updated:** 2025-11-11
**Next Review:** Prefix Management Protocol (PMP) Session 1 completed, 3 sessions remaining
